---
title: "Choosing A Model"
author: "zoontutorials team"
date: "7 March 2017"
output:
  rmarkdown::html_vignette:
    toc: yes
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Choosing A Model}
  %\VignetteEncoding{UTF-8}
---

# Introduction

With the abundance of species distribution modelling (SDM) algorithms to pick from, one might find themselves asking which model to choose? Some models can only be implemented on certain types of data, they can fall into the schools of 'profile', 'regression', or 'machine learning' based methods (although 'profile' methods are currently not implemented in `zoon`), and even within these schools there can be significant differences in how different models operate.

So, which model should you choose to fit to your dataset? In this best practice guide we can into detail about the common SDM model types available in `zoon`. For each model we will cover which data types it is compatible with, explain the underlying statistical approach, and show you how to fit the model in `zoon`.

Throughout this tutorial we will fit several example SDMs to highlight each model, and to keep comparisons straight forward we will fit them all to the same Carolina Wren dataset, standardise our covariates, and generate 1000 points of background data.


# Models

## Regression-based Models

Regression analysis is a statistical method for estimating the relationships among variables, and the models found in this category are likely to be familiar to those with a statistical background. These models focus on the relationship between a dependent variable (like the presence of a species) and one or more independent variables (like our environmental predictor variables). The two regression-based SDMs covered here are logistic regression and generalised additive models.

### Logistic Regression

Logistic regression is a type of Generalised Linear Model (GLM) that can be fit to presence-background and presence-absence datasets. It uses the logit link function to estimate probability of a binary response variable (presence represented as "1" and absence as "0," for example) based on its relationship with one or more independent predictor variables. **insert example formula?**. The regression coefficients are estimated using maximum likelihood estimation. This method chooses parameter values that maximise the likelihood of observing the data given the parameters. 

The `LogisticRegression` model fits a logistic regression model to your data using the `glm` package in R. There are no additional arguments to define for this model, so to fit it requires only seleting it as your model module within your `workflow`.

```{r eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=7}
logistic_regression_workflow <- workflow(occurrence = CarolinaWrenPO,
                                         covariate = CarolinaWrenRasters,
                                         process = StandardiseCov,
                                         model = LogisticRegression,
                                         output = PrintMap)
```

### Generalised Additive Model

In contrast to GLMs, in which the coefficient for each covariate is estimated, in Generalised Additive Models (GAMs) the linear predictor is the sum of smoothing functions fit to each measured variable. **(Add definition of smoothing functions?)**. This model can be fit to presence-background and presence-absence datasets. The `mgcv` module fits a GAM using generalised cross-validation via the `mgcv` package. To fit this model you need to define a basis dimension used to represent the smooth term, and a two-letter character string indicating the smoothing basis to use. You select this model in your `workflow` as follows:

```{r eval=FALSE}
model = mgcv(k = -1,   # default settings
             bs = "tp")
```

### MaxEnt

MaxEnt is the most widely used SDM algorithm **(Elith reference)** today. This is a machine learning method that computes a probability distribution over the environment data grid cells, and the chosen distribution is the one that maximises the entropy (hence, MaxEnt), subject to some constraints. This method works with presence-background data. The `MaxEnt` module uses the `maxent()` function in the `dismo` package, and requires a MaxEnt executable file saved in the correct location. The `zoon` helper function `GetMaxEnt()` is available to help with this installation. You select this model in your `workflow` as follows:

```{r eval=FALSE}
model = MaxEnt
```

### Boosted Regression Trees

Boosted regression trees (BRTs; also known as Gradient Boosting Machine, or GBM), are a machine learning technique that produces a prediction model in the form of an ensemble of weak prediction models (i.e. decision trees). This differs from the standard regression approach of fitting a single best model by using the "boosting" technique to combine relatively large numbers of simple trees adaptively, optimising predictive performance. The `GBM` module fits a generalised boosted regression model using the `gbm` package. For this model you need to define the maximum number of trees, the maximum depth of variable interactions, and a shrinkage parameter (aka the learning rate). This model can be fit to presence-background and presence-absence data using the following call in your `workflow`:

```{r eval=FALSE}
model = GBM(max.trees = 1000,   # default values
            interaction.depth = 5,
            shrinkage = 0.001)
```

### RandomForest

Similar to the boosted regression trees in the `GBM` module, random forests are a machine learning technique that make use of an ensemble of weak prediction models (i.e. decision trees). Random forests differ from BRTs by fitting each decision tree independently from previously fit trees using bootstrapped samples of your data. **(need a better definition of the difference between BRT and RF?)**. The `RandomForest` module can be fit to presence-background or presence-absence data using the following call in your `workflow`:

```{r eval=FALSE}
model = RandomForest
```
